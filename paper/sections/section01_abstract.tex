This paper presents a novel approach for detecting deepfake videos using Vision Transformers (ViTs) combined with Binary Cross Entropy (BCE) as the loss function during training and evaluation. With the proliferation of manipulated video content, effective detection methods are crucial for maintaining trust in digital media. Our method leverages the self-attention mechanism of ViTs to capture complex temporal dependencies across frames, enhancing feature extraction capabilities compared to traditional convolutional networks. We utilize two prominent datasets, FaceForensics and Celebs Deepfake, which provide a diverse range of manipulated video sequences for robust training and testing. The BCE loss function is employed to optimize model performance, particularly in binary classification tasks, by effectively measuring the difference between predicted probabilities and actual labels. Experimental results demonstrate that our approach achieves superior accuracy in identifying deepfake videos, highlighting the potential of ViTs in combating digital misinformation.